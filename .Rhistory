library(rpart)
library(rpart.plot)
library(genefilter)
library(cvTools)
library(class)
library (dplyr)
library(sparsediscrim)
library(cvTools)
gsm <- getGEO("GSE4882", GSEMatrix = TRUE)
gse <- getGEO("GSE4882", GSEMatrix = FALSE)
gsms <- GSMList(gse)
gpl <- GPLList(gse)
set.seed(69)
tdata <- t(testing)
valueSet1a <- tdata[folds == 1,]
valueSet2a <- tdata[folds == 2,]
#split the data
gclass <- as.factor(new_tdfn$faux_death)
classSet1a <- gclass[folds == 1]
classSet2a <- gclass[folds == 2]
cvRes = cvTruth = c()
cv.knn.predict1 = knn(train = valueSet1a, test = valueSet2a, cl = classSet1a, k = 2)
cv.knn.predict2 = knn(train = valueSet2a, test = valueSet1a, cl = classSet2a, k = 2)
allActuala <- c(as.character(classSet1a), as.character(classSet2a))
cv.knn.predict <- c(as.character(cv.knn.predict1), as.character(cv.knn.predict2))
cv.knn.confusion <- table(Actual = allActuala, Predicted = cv.knn.predict)
cv.knn.confusion
accuracy=sum(diag(cv.knn.confusion))/sum(cv.knn.confusion)
accuracy
balancederrorrate=mean((rowSums(cv.knn.confusion) - diag(cv.knn.confusion))/rowSums(cv.knn.confusion))
balancederrorrate
#cvTruth = c(cvTruth, allActuala)
#cvRes = c(cvRes, as.vector(cv.knn))
#cvRes
#cM = table(cvRes, cvTruth)
#cM
#Balanced error rate
#val = (cM[2,1] / colSums(cM)[1]) + (cM[1,2] / colSums(cM)[2])
#round(val,2)
set.seed(69)
#folds = cvFolds(#IDs, K = 10)
folds = cvFolds(ncol(testing), K = 10)
#
foldlist = split(folds$subsets, folds$which)
cvRes = cvTruth = c()
for (i in 1:10) {
TSindex = foldlist[[i]]
#create dfs where gene is rowname, ID is colname
LS = testing[,-TSindex]
TS = testing[,TSindex]
classLS <- as.factor(new_tdfn$faux_death)[-TSindex]
#because ID is colname, need to t() the df
trainedSet = dlda(t(LS), classLS)
DLDApredictedSet2 <- predict(trainedSet, t(TS))[["class"]]
cvTruth = c(cvTruth, as.factor(new_tdfn$faux_death)[TSindex])
cvRes = c(cvRes, as.vector(DLDApredictedSet2))
}
cvRes
cM = table(cvRes, cvTruth)
print('Overall accuracy is: ')
val = sum(diag(cM)) / length(cvRes)
round(val,2)
print('Balanced error rate is: ')
val = (cM[2,1] / colSums(cM)[1]) + (cM[1,2] / colSums(cM)[2])
round(val,2)
#Comparison of DLDA 2fold vs 5fold
table(cvRes, DLDApredictAll)
install.packages("NMF", dependencies = TRUE)
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library("GEOquery")
library("survival")
library("survminer")
library("RColorBrewer")
library(rpart)
library(rpart.plot)
library(genefilter)
library(cvTools)
library(class)
library (dplyr)
library(sparsediscrim)
library(NMF)
gsm <- getGEO("GSE4882", GSEMatrix = TRUE)
gse <- getGEO("GSE4882", GSEMatrix = FALSE)
gsms <- GSMList(gse)
gpl <- GPLList(gse)
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
h1 <- aheatmap(t(actually_ordered1_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#***cohort2***
ordered2 <- cohort2[order(cohort2$risk),]
actually_ordered2 <- ordered2[,y]
actually_ordered2_1=actually_ordered2[,ncol(actually_ordered2):1]
h2 <- aheatmap(t(actually_ordered2_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#plot heatmaps in grid.
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#***cohort2***
ordered2 <- cohort2[order(cohort2$risk),]
actually_ordered2 <- ordered2[,y]
actually_ordered2_1=actually_ordered2[,1:ncol(actually_ordered2)]
h2 <- aheatmap(t(actually_ordered2_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#plot heatmaps in grid.
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), scale = "none", Colv = NA, Rowv = NA, scale="column", col=hmcols)
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), scale = "none", legend = TRUE, Colv = NA, Rowv = NA, scale="column", col=hmcols)
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), scale = "none", Colv = NA, Rowv = NA, scale="column", col=hmcols)
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), legend = FALSE, Colv = NA, Rowv = NA, scale="column", col=hmcols)
#***cohort2***
ordered2 <- cohort2[order(cohort2$risk),]
actually_ordered2 <- ordered2[,y]
actually_ordered2_1=actually_ordered2[,1:ncol(actually_ordered2)]
h2 <- aheatmap(t(actually_ordered2_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#plot heatmaps in grid.
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#***cohort2***
ordered2 <- cohort2[order(cohort2$risk),]
actually_ordered2 <- ordered2[,y]
actually_ordered2_1=actually_ordered2[,1:ncol(actually_ordered2)]
h2 <- aheatmap(t(actually_ordered2_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#plot heatmaps in grid.
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
library("GEOquery")
library("survival")
library("survminer")
library("RColorBrewer")
library(rpart)
library(rpart.plot)
library(genefilter)
library(cvTools)
library(class)
library (dplyr)
library(sparsediscrim)
library(NMF)
gsm <- getGEO("GSE4882", GSEMatrix = TRUE)
gse <- getGEO("GSE4882", GSEMatrix = FALSE)
gsms <- GSMList(gse)
gpl <- GPLList(gse)
pdata <- pData(gsm[[1]])
expd <- exprs(gsm[[1]])
expd <- gsm[[1]]@assayData$exprs
nobg_expd <- pmax(expd, 3000)
logged_expd <- log2(nobg_expd)
cov <- vector("numeric")
for (i in 1:672) {
cov[i] <- 100*(sd(logged_expd[i,])/mean(logged_expd[i,]))
}
cov3_true<-cov>3
#485 genes, logged and removed COV<3 (and corrected for background). Just need to quantilise the entire df/matrix now.
#ID as col name, gene as rows
logged_expd[!cov3_true,] <- NA
rownames(logged_expd) <- gpl$GPL3730@dataTable@table$Symbol
#Missing gene symbol is relevant to biomarker. Manually add in.
rownames(logged_expd)[469] <- "ZNF264"
#rownames_logged_expd <- rownames(logged_expd)
temporary <- logged_expd[complete.cases(logged_expd), ]
logged_expd3 <- temporary
rownames(logged_expd3) <- rownames(temporary)
# logged_expd3[] = ceiling(rank(logged_expd3)/length(logged_expd3)*4)
#logged_expd3 is 485 genes quantised 1:4, paper doesnt say why (in methods or supp methods)
risk_genes = c("NF1", "HGF", "HMMR", "IRF4", "ZNF264", "ERBB3",
"STAT2", "CPEB4", "RNF4", "DUSP6", "MMD",
"DLG2", "ANXA5", "LCK", "FRAP1", "STAT1")
in_risk_list <- rownames(logged_expd3) %in% risk_genes
#1:4 levels of expression, df with ZNF264 label in correct
rownames(logged_expd3)[in_risk_list]
new_tdfn <- t(logged_expd3[in_risk_list,])
x <- c()
for (i in 1:125) {
x[i] <- paste('id', i, collapse="", sep="_")
}
rownames(new_tdfn) <- x
new_tdfn <- cbind(new_tdfn, pdata[,40:45])
colnames(new_tdfn)[17:22] <- c("Age", "Stage", "Cell_type", "Gender","Met", "Survival")
new_tdfn <- as.data.frame(new_tdfn)
new_tdfn[,c(1:17, 21:22)] <- sapply(new_tdfn[,c(1:17, 21:22)], as.numeric)
coeffs <- c(0.52, -0.84, -1.09, 0.52, 0.59, 0.55, 0.47, 1.32, 0.51, 0.59, 0.55, 0.92, 0.65, -0.77, -0.58, 0.75)
new_tdfn$risk <- rowSums(mapply('*', new_tdfn[,1:16], coeffs))
new_tdfn[,1:16]<- new_tdfn[,c(3 ,14 , 13, 4, 7, 6, 1, 12, 2, 8, 5, 11, 9, 15, 16, 10)]
#use y to sort whenever needed
y <- c("NF1", "HGF", "HMMR", "IRF4", "ZNF264", "ERBB3",
"STAT2", "CPEB4", "RNF4", "DUSP6", "MMD",
"DLG2", "ANXA5", "LCK", "FRAP1", "STAT1")
#creating faux_death
metastasis <- as.numeric(pdata$`Survival time (month):ch1`)-as.numeric(pdata$`Metastasis time (month):ch1`)
new_tdfn$faux_death <- metastasis>.028
table(new_tdfn$faux_death)
testing<- logged_expd3[!duplicated(rownames(logged_expd3)),]
Tstatistics = rowttests(testing,as.factor(new_tdfn$faux_death), tstatOnly = TRUE)
head(Tstatistics)
best100T <- order(abs(Tstatistics[, "statistic"]), decreasing = TRUE)[1:100]
testing <- testing[best100T, ]
dim(testing)
boxplot(logged_expd3["FRAP1",] ~ new_tdfn$faux_death)
logged_expd3[] = ceiling(rank(logged_expd3)/length(logged_expd3)*4)
#logged_expd3 is 485 genes quantised 1:4, paper doesnt say why (in methods or supp methods)
risk_genes = c("NF1", "HGF", "HMMR", "IRF4", "ZNF264", "ERBB3",
"STAT2", "CPEB4", "RNF4", "DUSP6", "MMD",
"DLG2", "ANXA5", "LCK", "FRAP1", "STAT1")
in_risk_list <- rownames(logged_expd3) %in% risk_genes
#1:4 levels of expression, df with ZNF264 label in correct
rownames(logged_expd3)[in_risk_list]
new_tdfn <- t(logged_expd3[in_risk_list,])
x <- c()
for (i in 1:125) {
x[i] <- paste('id', i, collapse="", sep="_")
}
rownames(new_tdfn) <- x
new_tdfn <- cbind(new_tdfn, pdata[,40:45])
colnames(new_tdfn)[17:22] <- c("Age", "Stage", "Cell_type", "Gender","Met", "Survival")
new_tdfn <- as.data.frame(new_tdfn)
new_tdfn[,c(1:17, 21:22)] <- sapply(new_tdfn[,c(1:17, 21:22)], as.numeric)
coeffs <- c(0.52, -0.84, -1.09, 0.52, 0.59, 0.55, 0.47, 1.32, 0.51, 0.59, 0.55, 0.92, 0.65, -0.77, -0.58, 0.75)
new_tdfn$risk <- rowSums(mapply('*', new_tdfn[,1:16], coeffs))
new_tdfn[,1:16]<- new_tdfn[,c(3 ,14 , 13, 4, 7, 6, 1, 12, 2, 8, 5, 11, 9, 15, 16, 10)]
#use y to sort whenever needed
y <- c("NF1", "HGF", "HMMR", "IRF4", "ZNF264", "ERBB3",
"STAT2", "CPEB4", "RNF4", "DUSP6", "MMD",
"DLG2", "ANXA5", "LCK", "FRAP1", "STAT1")
#creating faux_death
metastasis <- as.numeric(pdata$`Survival time (month):ch1`)-as.numeric(pdata$`Metastasis time (month):ch1`)
new_tdfn$faux_death <- metastasis>.028
new_tdfn$ID<-1:125
cohort1_ID <- sample(x=1:nrow(new_tdfn),size = 0.5*nrow(new_tdfn))
cohort1 <- new_tdfn[new_tdfn$ID %in% cohort1_ID,]
cohort2 <- new_tdfn[!new_tdfn$ID %in% cohort1_ID,]
#****cohort1****
cohort1$high_risk <- cohort1$risk>median(cohort1$risk)
tdfn.as.high_risk1 <- survfit(Surv(cohort1$Survival, cohort1$faux_death) ~ high_risk, data=cohort1)
surv1 <- ggsurvplot(tdfn.as.high_risk1,data = cohort1, xlab = "Months",ylab="Overall Survival",legend.labs=c("Low-risk","High-risk"),palette = c( "#2E9FDF","#FF0000"))
#****cohort2****
cohort2$high_risk <- cohort2$risk>median(cohort2$risk)
tdfn.as.high_risk2 <- survfit(Surv(cohort2$Survival, cohort2$faux_death) ~ high_risk, data=cohort2)
surv2 <- ggsurvplot(tdfn.as.high_risk2,data = cohort2, xlab = "Months",ylab="Overall Survival",legend.labs=c("Low-risk","High-risk"),palette = c( "#2E9FDF","#FF0000"))
splots <- list()
splots[[1]] <- surv1
splots[[2]] <- surv2
arrange_ggsurvplots(splots, print = TRUE,
ncol = 2, nrow = 1, risk.table.height = 0.4)
#****cohort1****
tdfn.as.NoRelapse.high_risk1 <- survfit(Surv(cohort1$Met, cohort1$faux_death) ~ high_risk, data=cohort1)
surv3 <- ggsurvplot(tdfn.as.NoRelapse.high_risk1,data = cohort1, xlab = "Months",ylab="%Relapse-free Survival",legend.labs=c("Low-risk","High-risk"),palette = c( "#2E9FDF","#FF0000"))
#****cohort2****
tdfn.as.NoRelapse.high_risk2 <- survfit(Surv(cohort2$Met, cohort2$faux_death) ~ high_risk, data=cohort2)
surv4 <- ggsurvplot(tdfn.as.NoRelapse.high_risk2,data = cohort2, xlab = "Months",ylab="%Relapse-free Surviva",legend.labs=c("Low-risk","High-risk"),palette = c( "#2E9FDF","#FF0000"))
splots2 <- list()
splots2[[1]] <- surv3
splots2[[2]] <- surv4
arrange_ggsurvplots(splots2, print = TRUE,
ncol = 2, nrow = 1, risk.table.height = 0.4)
par(mfrow=c(1,2))
hmcols<-colorRampPalette(c("blue","white","red"))(256)
#***cohort1***
ordered1 <- cohort1[order(cohort1$risk),]
actually_ordered1 <- ordered1[,y]
actually_ordered1_1=actually_ordered1[,1:ncol(actually_ordered1)]
h1 <- aheatmap(t(actually_ordered1_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#***cohort2***
ordered2 <- cohort2[order(cohort2$risk),]
actually_ordered2 <- ordered2[,y]
actually_ordered2_1=actually_ordered2[,1:ncol(actually_ordered2)]
h2 <- aheatmap(t(actually_ordered2_1), Colv = NA, Rowv = NA, scale="column", col=hmcols)
#plot heatmaps in grid.
hmcols2<-colorRampPalette(c("blue","red"))(256)
newdf<- logged_expd[complete.cases(logged_expd), ]
newdf<-t(newdf)
x <- c()
for (i in 1:125) {
x[i] <- paste('id', i, collapse="", sep="_")
}
rownames(newdf) <- x
in_risk_list <- colnames(newdf) %in% risk_genes
new_df2 <- newdf[,in_risk_list]
new_df2 <- new_df2[,y]
new_df2=new_df2[,ncol(new_df2):1]
overall_heatmap <- heatmap(t(as.matrix(new_df2[order(new_tdfn$risk),])), Colv = NA, Rowv = NA, scale="column", col=hmcols2)
overall_heatmap
set.seed(1)
rtree_fit <- rpart(faux_death ~ DUSP6+ MMD+ STAT1+ERBB3+LCK, cohort2)
pfit<- prune(rtree_fit, cp=0.0125)
rpart.plot(pfit)
printcp(rtree_fit)
set.seed(69)
classes <- as.factor(new_tdfn$faux_death)
folds <- cvFolds(ncol(testing), K = 2)$which
valuesSet1 = testing[, folds == 1]
valuesSet2 = testing[, folds == 2]
classesSet1 = classes[folds == 1]
classesSet2 = classes[folds == 2]
trainedSet1 = dlda(t(valuesSet1), classesSet1)
DLDApredictedSet2 = predict(trainedSet1, t(valuesSet2))[["class"]]
trainedSet2 = dlda(t(valuesSet2), classesSet2)
DLDApredictedSet1 = predict(trainedSet2 , t(valuesSet1))[["class"]]
allActual <- c(as.character(classesSet1), as.character(classesSet2))
DLDApredictAll <- c(as.character(DLDApredictedSet1), as.character(DLDApredictedSet2))
DLDAconfusion <- table(Actual = allActual, Predicted = DLDApredictAll)
DLDAconfusion
accuracy=sum(diag(DLDAconfusion))/sum(DLDAconfusion)
accuracy
errorrate=1 - sum(diag(DLDAconfusion))/sum(DLDAconfusion)
balancederrorrate=mean((rowSums(DLDAconfusion) - diag(DLDAconfusion))/rowSums(DLDAconfusion))
balancederrorrate
precision= DLDAconfusion["TRUE", "TRUE"]/sum(DLDAconfusion[, "TRUE"])
set.seed(69)
#folds = cvFolds(#IDs, K = 10)
folds = cvFolds(ncol(testing), K = 10)
#
foldlist = split(folds$subsets, folds$which)
cvRes = cvTruth = c()
for (i in 1:10) {
TSindex = foldlist[[i]]
#create dfs where gene is rowname, ID is colname
LS = testing[,-TSindex]
TS = testing[,TSindex]
classLS <- as.factor(new_tdfn$faux_death)[-TSindex]
#because ID is colname, need to t() the df
trainedSet = dlda(t(LS), classLS)
DLDApredictedSet2 <- predict(trainedSet, t(TS))[["class"]]
cvTruth = c(cvTruth, as.factor(new_tdfn$faux_death)[TSindex])
cvRes = c(cvRes, as.vector(DLDApredictedSet2))
}
cvRes
cM = table(cvRes, cvTruth)
print('Overall accuracy is: ')
val = sum(diag(cM)) / length(cvRes)
round(val,2)
print('Balanced error rate is: ')
val = (cM[2,1] / colSums(cM)[1]) + (cM[1,2] / colSums(cM)[2])
round(val,2)
#Comparison of DLDA 2fold vs 5fold
table(cvRes, DLDApredictAll)
set.seed(69)
tdata <- t(testing)
valueSet1a <- tdata[folds == 1,]
set.seed(69)
tdata <- t(testing)
valueSet1a <- tdata[,folds == 1]
folds
class(folds)
class(folds$which)
folds <- cvFolds(ncol(testing), K = 2)$which
class(folds$which)
class(folds)
set.seed(69)
classes <- as.factor(new_tdfn$faux_death)
folds <- cvFolds(ncol(testing), K = 2)$which
valuesSet1 = testing[, folds == 1]
valuesSet2 = testing[, folds == 2]
classesSet1 = classes[folds == 1]
classesSet2 = classes[folds == 2]
trainedSet1 = dlda(t(valuesSet1), classesSet1)
DLDApredictedSet2 = predict(trainedSet1, t(valuesSet2))[["class"]]
trainedSet2 = dlda(t(valuesSet2), classesSet2)
DLDApredictedSet1 = predict(trainedSet2 , t(valuesSet1))[["class"]]
allActual <- c(as.character(classesSet1), as.character(classesSet2))
DLDApredictAll <- c(as.character(DLDApredictedSet1), as.character(DLDApredictedSet2))
DLDAconfusion <- table(Actual = allActual, Predicted = DLDApredictAll)
DLDAconfusion
accuracy=sum(diag(DLDAconfusion))/sum(DLDAconfusion)
accuracy
errorrate=1 - sum(diag(DLDAconfusion))/sum(DLDAconfusion)
balancederrorrate=mean((rowSums(DLDAconfusion) - diag(DLDAconfusion))/rowSums(DLDAconfusion))
balancederrorrate
precision= DLDAconfusion["TRUE", "TRUE"]/sum(DLDAconfusion[, "TRUE"])
set.seed(69)
folds <- cvFolds(ncol(testing), K = 2)$which
tdata <- t(testing)
valueSet1a <- tdata[,folds == 1]
set.seed(69)
folds <- cvFolds(ncol(testing), K = 2)$which
tdata <- t(testing)
valueSet1a <- tdata[folds == 1,]
valueSet2a <- tdata[folds == 2,]
#split the data
gclass <- as.factor(new_tdfn$faux_death)
classSet1a <- gclass[folds == 1]
classSet2a <- gclass[folds == 2]
cvRes = cvTruth = c()
cv.knn.predict1 = knn(train = valueSet1a, test = valueSet2a, cl = classSet1a, k = 2)
cv.knn.predict2 = knn(train = valueSet2a, test = valueSet1a, cl = classSet2a, k = 2)
allActuala <- c(as.character(classSet1a), as.character(classSet2a))
cv.knn.predict <- c(as.character(cv.knn.predict1), as.character(cv.knn.predict2))
cv.knn.confusion <- table(Actual = allActuala, Predicted = cv.knn.predict)
cv.knn.confusion
accuracy=sum(diag(cv.knn.confusion))/sum(cv.knn.confusion)
accuracy
balancederrorrate=mean((rowSums(cv.knn.confusion) - diag(cv.knn.confusion))/rowSums(cv.knn.confusion))
balancederrorrate
set.seed(69)
classes <- as.factor(new_tdfn$faux_death)
folds <- cvFolds(ncol(testing), K = 2)$which
valuesSet1 = testing[, folds == 1]
valuesSet2 = testing[, folds == 2]
classesSet1 = classes[folds == 1]
classesSet2 = classes[folds == 2]
trainedSet1 = dlda(t(valuesSet1), classesSet1)
DLDApredictedSet2 = predict(trainedSet1, t(valuesSet2))[["class"]]
trainedSet2 = dlda(t(valuesSet2), classesSet2)
DLDApredictedSet1 = predict(trainedSet2 , t(valuesSet1))[["class"]]
allActual <- c(as.character(classesSet1), as.character(classesSet2))
DLDApredictAll <- c(as.character(DLDApredictedSet1), as.character(DLDApredictedSet2))
DLDAconfusion <- table(Actual = allActual, Predicted = DLDApredictAll)
DLDAconfusion
accuracy=sum(diag(DLDAconfusion))/sum(DLDAconfusion)
accuracy
errorrate=1 - sum(diag(DLDAconfusion))/sum(DLDAconfusion)
balancederrorrate=mean((rowSums(DLDAconfusion) - diag(DLDAconfusion))/rowSums(DLDAconfusion))
balancederrorrate
precision= DLDAconfusion["TRUE", "TRUE"]/sum(DLDAconfusion[, "TRUE"])
set.seed(69)
#folds = cvFolds(#IDs, K = 10)
folds1 = cvFolds(ncol(testing), K = 10)
#
foldlist = split(folds1$subsets, folds1$which)
cvRes = cvTruth = c()
for (i in 1:10) {
TSindex = foldlist[[i]]
#create dfs where gene is rowname, ID is colname
LS = testing[,-TSindex]
TS = testing[,TSindex]
classLS <- as.factor(new_tdfn$faux_death)[-TSindex]
#because ID is colname, need to t() the df
trainedSet = dlda(t(LS), classLS)
DLDApredictedSet2 <- predict(trainedSet, t(TS))[["class"]]
cvTruth = c(cvTruth, as.factor(new_tdfn$faux_death)[TSindex])
cvRes = c(cvRes, as.vector(DLDApredictedSet2))
}
cvRes
cM = table(cvRes, cvTruth)
print('Overall accuracy is: ')
val = sum(diag(cM)) / length(cvRes)
round(val,2)
print('Balanced error rate is: ')
val = (cM[2,1] / colSums(cM)[1]) + (cM[1,2] / colSums(cM)[2])
round(val,2)
#Comparison of DLDA 2fold vs 5fold
table(cvRes, DLDApredictAll)
set.seed(69)
tdata <- t(testing)
valueSet1a <- tdata[folds == 1,]
valueSet2a <- tdata[folds == 2,]
#split the data
gclass <- as.factor(new_tdfn$faux_death)
classSet1a <- gclass[folds == 1]
classSet2a <- gclass[folds == 2]
cvRes = cvTruth = c()
cv.knn.predict1 = knn(train = valueSet1a, test = valueSet2a, cl = classSet1a, k = 2)
cv.knn.predict2 = knn(train = valueSet2a, test = valueSet1a, cl = classSet2a, k = 2)
allActuala <- c(as.character(classSet1a), as.character(classSet2a))
cv.knn.predict <- c(as.character(cv.knn.predict1), as.character(cv.knn.predict2))
cv.knn.confusion <- table(Actual = allActuala, Predicted = cv.knn.predict)
cv.knn.confusion
accuracy=sum(diag(cv.knn.confusion))/sum(cv.knn.confusion)
accuracy
balancederrorrate=mean((rowSums(cv.knn.confusion) - diag(cv.knn.confusion))/rowSums(cv.knn.confusion))
balancederrorrate
set.seed(69)
cvRes = cvTruth = c()
for (i in 1:10) {
TSindex = foldlist[[i]]
LS = tdata[-TSindex,]
TS = tdata[TSindex,]
cv.knn = knn(train = LS, test = TS, cl = gclass[-TSindex], k = 10)
cvTruth = c(cvTruth, gclass[TSindex])
cvRes = c(cvRes, as.vector(cv.knn))
}
cvRes
## Confusion matrix
cM = table(cvRes, cvTruth)
print('Overall accuracy is: ')
val = sum(diag(cM)) / length(cvRes)
round(val,2)
print('Balanced error rate is: ')
val = (cM[2,1] / colSums(cM)[1]) + (cM[1,2] / colSums(cM)[2])
round(val,2)
table(cvRes, cv.knn.predict)
